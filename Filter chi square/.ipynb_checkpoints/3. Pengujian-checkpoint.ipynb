{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import load\n",
    "from modulku import praproses as pps, StemNstopW as stm\n",
    "from replace import normalisasi as nrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xx (teks):\n",
    "    if type(teks) is not str:\n",
    "        teks = str(teks)\n",
    "    teks = pps.preprocessing(teks)\n",
    "    teks = nrm.normalisasi(teks)\n",
    "    teks = stm.stemmer_kata(teks)\n",
    "    teks = stm.stop_word(teks)\n",
    "    if type(teks) is not str:\n",
    "        print(teks)\n",
    "    return teks\n",
    "\n",
    "def praproses (teks):\n",
    "    if type(teks) == list:\n",
    "        print(\"list\")\n",
    "        l = list()\n",
    "        for i in teks:\n",
    "            l.append(xx(i))\n",
    "        return l\n",
    "    else:\n",
    "        return [xx(teks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = load(\"model/tfidf.w\")\n",
    "svm = load(\"model/svm.m\") #\n",
    "mnb = load(\"model/mnb.m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_uji_253_spam_bersih\n",
    "data_uji = pd.read_excel(\"komentar/data_1.xlsx\") #data_1.xlsx\n",
    "data_uji = data_uji.fillna(\" \")\n",
    "komentar = data_uji.komentar.tolist()\n",
    "# label = data_uji.label.tolist()\n",
    "# data_uji\n",
    "len(data_uji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melakukan Prediksi terhadap data uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n",
      "orang miskin kaya g mungkin diam rumah pak hasil aja g punya anak bini sya mau kasih makan apa pak hari aja g kerja ga ketemu nasi pak bantu perintah aja g pernah rasa sama sekali jdi sya tetep kluar kerja tpi anak istri ttap rumah moga ja gada sana pak aaammiinn\n",
      "teman 2 sadar betapa penting nya rumah sulit apa kamu bangga bahaya orang banyak kamu pnya belas kasih banyak orang paksa keluar rumah sambung hdp bukan senang senang bukan nya becanda nyawa taruh nya tdk seru soal jadi korban tdk seru buat orang jadi sengsara saling bantu kurang sebar sakit covid jangan remeh sesal kemudi manusia manusia jangan angkuh karna kamu tau sebenernya kalau sikap sprti kamu berakhr gmn please stay at home\n",
      "rumah aja bgi bnr 2 gk prlu bgt lbh baik drmh buat krja krja aja tp ttp jaga sehat bersih diri brdoa jgn lupa\n",
      "serba salah keluar takut salahin gak keluar anak bini gak makan\n",
      "kl q d rumah keluarga ngasih makan siapa\n",
      "rumah aja klo kesitu aja\n",
      "mending mampir dulu kesini bang kenang 2annya selfie dulu sama keluarga\n",
      "rumah aja gua banyak pegawai usaha gk rumah aja\n",
      "maaf cuma komentar aja jangan terlalu ambil hati cuma om ntar aja gitu maksud jadi cuman ken tahu maksud foto depan kamar jenazah lucu kan jempol terus kasih tulis kalian rumah tunggu sini maksud apa emang bapak mana pulang dicariin tuh udah deh jangan nakut 2in gitu ye bpk sendiri gimana baek 2 aja kan\n",
      "asiyap bang hubung suami g kerja karna rumah udh tembok sempurna jd g dpt bantu ta jual almari kayu dulu buat hidup moga segera baik aamiin\n",
      "punten pak bilangin mamasnya kapan hp paketinnya gitu hahaha\n",
      "kamar paling yaman huni kaum erti dunia\n",
      "mantap bang selamat hari raya nyepi bang bal tradisional lockdown\n",
      "denger tu bang jgn dekat cewe aja bg ntar tular kirana bg\n",
      "kalau kaya sprti bng hotman rumah ja kalau rumah aja gal kena corona tpi mati kelapran\n",
      "jgn takut dgn virus corona allah jaga utama jaga bersih diri hati jaga wudhu dgn shalat waktu shalat sunnah nya sllu zikir bershalawat doa yakin kpd allah swt atas izin allah semua jadi izin allah tdk akn prnh jadi percaya yakin lah kpd allah klw org muslim\n",
      "mempan ga nh buat org indo otak dangkal susah atur\n",
      "ng omhae lah ape ra mangan ta iyo nk pegawai negeri ra kejo tetep bayar\n",
      "hohoho lebih baik dirumahsaja masuk situ\n",
      "kerja satpam gak kerja iya gak gajih mau gak mau kerja sapa sih gak mau rmh santai maen sama kluarga iya apa buat kluarga\n",
      "solusi tulang buat kaum 2 miskin lelang dulu cincin jari kemanusian\n",
      "elu tunggu situ keluarga elu sendiri\n",
      "milik tubuh tinggi badan ideal memang impi semua orang mau tau cara tambah tinggi cara alami cepat usia 24th kak yuk cek bukti ig aku\n",
      "nyata usia 27th nambah tinggi badan kak gak percaya yuk cek ig aku kak banyak testim 0ni udah bukti\n",
      "lebih baik rumah kalau luar jaga jarak \n",
      "rumah aja sama ajah kgk makan gk hasil sama bae lah d\n",
      "ibadah sholt jumat hntikn jenak pdahal ibadah wajib dlm msjid mlibatkn jama ah hingga ratus orang knp justru pabrik kryawanya ribu orang justru ttp d suruh bekrja ap arti buruh pabrik kebal corona\n",
      "seharj kerja hari makan gimana mau rumah pak klu bapak ngasi bantu km lama bapak suruh km diam rumah kt doa allah moga kt ttp dlm lindung nya lama kt kerja luar rumah ora etlabora suara rakyat kecill\n",
      "nyuruh diam drmh sp mo ksih mkn mikir dong\n",
      "sumbang hotman manani ga kedengeran gede vloger\n",
      "ak kerja sales tiap hari keliling ndak kerja gk makan\n",
      "betulsekali orang indonesia kan suka stubborn alias bandel singapore perlu lockdown rakyat discipline penuh sadar percaya perintah atas ayo indonesiabisa\n",
      "busett seremm laying down z d rmh\n",
      "mantapss bangg sok kebal n jago msh nongkrong 2 biar aja\n",
      "jual omm kurang\n",
      "biasa aja kali ngomong ng usah begini om\n",
      "mayat kena corona bang klo taro kamar jenazah\n",
      "rumah bang karna kerja libur gajih ikut libur\n",
      "tunggu sana tiba ruang bersih\n",
      "ambil hikmah pd mudah jgn jadi malas sekolah bener jd org sukses shg pas darurat spt manfaat tabung baru asa skali\n",
      "klee baju kaya seragam gais\n",
      "sehat 2 nya bpk tpi baju bpk kurang pake lah lindung pak ga cukup cuma masker tubuh bapk lindung sehat 2 nya bpk\n",
      "anjay singkat padat jelas takut\n",
      "bila punya harta banyak tetangga miskin bantu saling mampu mulai dr dulu cara efektif kurang keluar dr rumah\n",
      "sy ojol bang klo rumah sy ga dpt uang anak istri makan ap bang\n",
      "olahraga terus engga tinggi tinggi cacing \n",
      "pakai kata kata ku bilang jangan pergi keluar keluar mati lah kau\n",
      "smoga makin banyak sana mas\n",
      "krja silahkn pk and jga diri klo gk penting tetep rumah pk\n",
      "bang hotman bgmn mau tinggal rumah kalau tempat kerja izin\n",
      "tgu dsana aja lae tp mau sama lae\n",
      "nah pantas buat sengaja nongkrong 2 jalan 2 bandel maaf paksa kerja krn buat makan keluarga\n",
      "klo ojol atw krj hari kn emng g bs klo g nrik gd duit buat mkn cr duit jg kn bukn buat mkn aj byr kontrakn listrik kmren demo 2 mkanan buat demo pdhal skrg btuh bntuan tp gda 2 tp msh cust baik order mknan tp buat driver mknannya klo lockdown sp mw ngsih mkn klo perintah jg ky ny psti kena sasar aplgia pkerja hrian bnyk bgt efektif bntu sbnr ny tetangga mampu nolong g mampu cuma syng ny bnyk org g peka sm keliling tmpt sy bnyk org kaya mobil bnyk rumah bnyk hrusny mreka bntu masak ttngga g mampu aj udh bntu\n",
      "salam kenall bang buka dulu sy punya postingan ig semuanyaa selisih faham jalan irama sama sosmed kata gossip hebat bejat oke bang selamat ajar tuju pintar putar putar fokus tuju altar sila 1 tuhan maha esa\n",
      "tinggi badan laris dunia banyak bukti usia 22th naik\n",
      "mau rumah aja lama wabah sy makan apa bingung ken rumah jg isolasi diri aman diri dr covid tp balik makan apa \n",
      "stay at home kalau gk perlu\n",
      "nasehat lebih baik drpd beri shock terapi takut timbul cemas tingkat tinggi lalu antibody drop lalu virus non colorna masuk lalu kata colorna krn musim kasihan masyrakat plus\n",
      "semua alas perut dr sayang nyawa klu mau disiplin bukan satu alas contoh jalan puasa ramadhan disiplin niat\n",
      "tunggu aja lah silah tetap keluar kerja perintah mau nanggung segala perlu keluarga\n",
      "konglomerat rumah gak masalah nah punya tanggung gimana\n",
      "umurr keataas ledekiin boncel makanya upgrade tinggi mu 4 18cm hitung hari lh cek bio\n",
      "hai nitizen hormat koment 2 selalu bawa nama org kecil hari ga kerja ga makan baca mikir dgn akal sehat org 2 koment punya akun ig main hp perlu quota tiap hari dr mana arti org punya duit cuma atas nama org kecil buat manas 2in suasana dlm begini bantu alangkah lebih baik dr buat resah\n",
      "mauu tiinggii badann usiia taahun atas yukk kepoiinn ig \n",
      "suddah terllambatt usiia pertumbuhann masiih pengenn ttinggii yukk keppoinn ig \n",
      "terus kerja sedang seluruh malaysia libur total\n",
      "jangan ah smga derita 2 sembuh tuhan maha kuasa\n",
      "punya tinggi ideaal males olahragaa solusi tinggi naik 3 17cm cek ig \n",
      "maaf bang ojol keluar rumah kerja jalan bukan mau ikut anjur perintah kalau keluar rumah bagaimana tanggung jawab nafkah keluarga mending kalau punya tabung kerja sering cukup perlu hari 2 kalau kerja mungkin lebih pilih kamar mayat kalau memang jadi takdir diam diri lihat anak istri lapar semogakitasemuasehat semogasegalapenyakithilang moga semua selalu lindung allah s w t aamiin\n",
      "malu dikatain bogel terus sama temen kamu tenang punya solusi soal produk tinggi baadan langsung konsultasi ajaa\n",
      "kalo msh bebal kayak emang masuk situ\n",
      "pak sya driver ojol klo gk kluar buat ngebid anak istri sya makan apa blom listrik cicil mtor kontra kta orng lbih baik mati klaparan pda mati krna corona skrang sya mau tanya kalian tega emang klo driver ojol keluarga mati klaparan pdhl bantu dri mana bantu tetap rumah cegah corona tpi tetap harap manusia harap allah maha kuasa tpi krna bantu dri mana tetap luar ngebid cari nafkah buat anak istri rumah wlwpun sejak corona driver kena dampak nya sperti order smakin kurang trun drastis slama corona sya ngebid cuma dpt 2 3 tari paling dpt ribu smpe 40ribu nya anak istri sya ktmu nasi garam udh sngat syukur banget andai semua tau sperti simalakama\n",
      "sadis tys lindung k mna kmi amin\n",
      "nambahh tiinggii badann 10cm dllm 2miingguu kapann yukk kepoiinn ig \n",
      "gk penting bngt jgn keluar dirumahaja paksa kerja utk keluarga semngt utk klian saudara ingat keepsafety pke masker sarung tangan selalu jaga bersih masuk rumah keluarga kalian aman\n",
      "nama indonesia labil gilir suruh masuk kerja terkadang malas sekarang suruh perintah mau kerja krn takut mikirin cicil\n",
      "kasih rambu 2 zona kontaminasi orang takut\n",
      "bapa mau diruma bapa makan apa kalao buka beng kel makan apa pa kasi solusi bapa was 2 bapa\n",
      "siapin stok buat skluarga gue dlu bang hotman baru gue bner 2 rumah\n",
      "tunggu smpai mati lapar drumah\n",
      "wakakaa kget pak ancamane rmh aja pak selamat tugas sehat pak \n",
      "aq rumah pak keluarga siap duduk rumah apa keadaanya ayo kawan patuh anjur jangan mbakang aman sendiri moga corona cepat lalu normal mula\n",
      "\n",
      "jd kalau ngk keluar jd mkan apa\n",
      "bagus kalau semua i work trs rmh siapa\n",
      "si tetap keluar rumah kerja kerja tidah kerja mau beli mkn pake apa mati lapar rumah karana gk makan gk kerja\n",
      "bpak tunggu aja situ tunggu rumah \n",
      "yuuk intiip caraa baik menambaah tinggi 3 cm hitungann miinggu wloo umur diatass tahuun\n",
      "iy drumah aja kan hari libur\n",
      "ngak nasib singgle mom puter otak gmn ekonomi bsk sedang rumah aja kerja libur\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ina kasihbpara tugas moga kuat dl menjnkan tugas manusia gbu\n",
      "kampung aman bang hidup desa jauh ramai\n",
      "mnding usaha d rumah gk hasil gak pasu virus bukan dlihat mata telanjang diam d rumah tetap aja masuk nama sakit manusia butuh cahaya matahari oxigen langsung paham\n",
      "jangan 2 nungguin sdh lewat bang\n",
      "rakyat kecil andal makan keringat hasil bumi yakin tuhan punya semua solusi asal mau ikhtiar diam diri bukan solusi\n",
      "ga mau masuk kamar mayat biar jadi mayat takut tular color na hejo\n",
      "gaada nalangin beli beras rumah\n",
      "whay kalo ga keluar ngasih makan orang tua sapa tulang punggung keluarga\n",
      "jgn takut 2 i donk pa lebih bijak tenang lama wabah landa indonesia banyak kepala rumah tangga tengah bawah slalu kerja cari nafkah utk gaji punya tunjang kantor mungkin diam rumah\n",
      "rumah kali aja mr hotman mao subsidi kelurga kmi smua\n",
      "moga corona cepat lalu tdk lg hidup dgn cemas amin\n",
      "memang kerja kerja aja himbau nongkrong makan tempat kumpul kumpul kl usaha makan gak larang cuma himbau kalo bungkus bawa pulang\n",
      "pak hotman paris suara terhotmat bapak kerja sapu jalan ppsu dkk kerja lapang bersih tetap jaga bersih dki selamat ancam dgn virus corona keluarga anak istri tunggu rumah salah istri ppsu tahu kena bawa virus apa luar sana jalan tugas wajib jaga bersih kota jakarta sangat mohon bantu bijaksana beri kerja lapang mohon beri apd terimakasih\n",
      "co lia dlu om gode dr dr dr post cu\n",
      "sepupu gw nih keren bang\n",
      "rest in home or rest in peace\n",
      "satu sisi sih baik diam drumah gk kena virus korona klo orang kaya sih diam drumah asik asik aza klo orang pas pas diam drumah anak bini mau makan apa dong tpi mudah mudah virus corona cepat lalu amin\n",
      "anjayy depan kamar mayat selfie jempol\n",
      "arti ga diam rumah kena corona kena virus corona mati donk\n",
      "kan udah tua udah deket\n",
      "terus buruh pabrik gimana klo kerja bayar klo ga kerja ga bayar pilih kamar jenazah deh\n",
      "ampun bgi susah utk mngerti\n",
      "iya tahan kbutuhan pokok mulai goyang lebih takut sakit gk jenguk sakaratul maut gk nan takut bgt\n",
      "kene golek duwek gawe mangan mene bos\n",
      "bang hotman apa daya rumah klw ngk dana buat nganggur sama aja maju mati mudur mati\n",
      "orang susah kayak gue gak mungkin diem rumah punya saudara kaya raya gak buat apa apa\n",
      "ken siih gitu rumah aja suami gak tak bolehin kerja luar kota tpi semua tuntut kerja kalo ga kerja pecat terus keluarga rumah makan apa nyari kerja ga mudah bayang pak perintah udah nyiapain segala butuh makan cukup semua kerja bener 2 stop rumah aja\n",
      "salam lebih parah adaww pak postingannya\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-401b6e063cbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkomentar_praproses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpraproses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkomentar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhasil_predisksi_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkomentar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhasil_predisksi_mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkomentar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                    \"be removed in 0.24.\")\n\u001b[1;32m   1897\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "komentar_praproses = praproses(komentar)\n",
    "hasil_predisksi_svm = svm.predict(tfidf.transform(komentar))\n",
    "hasil_predisksi_mnb = mnb.predict(tfidf.transform(komentar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictt = {\n",
    "    \"komentar\":komentar_praproses,\n",
    "    \"label\":label\n",
    "}\n",
    "df = pd.DataFrame.from_dict(dictt)\n",
    "df.to_excel(\"komentar/data_1_labeled.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non spam \n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "# labels = list(reversed(list(set(label))))\n",
    "labels = list(set(label))\n",
    "y_true = label\n",
    "for i in labels:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0]\n",
      " [  0 250]]\n",
      " accuracy: 0.99\n",
      "precision: 1.0\n",
      "   recall: 1.0\n",
      "       f1: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = hasil_predisksi_mnb\n",
    "cf = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "print(cf)\n",
    "tn, fp, fn, tp = cf.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "print(\" accuracy:\",round(accuracy_score(y_true, y_pred), 2))\n",
    "print(\"precision:\",precision)\n",
    "print(\"   recall:\",recall)\n",
    "print(\"       f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 0, 0, 0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'non spam', 'spam'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0]\n",
      " [  0 250]]\n",
      " accuracy: 0.9881422924901185\n",
      "precision: 1.0\n",
      "   recall: 1.0\n",
      "       f1: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = hasil_predisksi_svm\n",
    "cf = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "print(cf)\n",
    "tn, fp, fn, tp = cf.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "print(\" accuracy:\",accuracy_score(y_true, y_pred))\n",
    "print(\"precision:\",precision)\n",
    "print(\"   recall:\",recall)\n",
    "print(\"       f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
