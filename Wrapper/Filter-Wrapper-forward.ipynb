{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngamelzz/Spam_Detection/blob/master/Wrapper/Filter-Wrapper-forward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CzjTelUVyFkv",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Del3hgyTNEk5"
      },
      "source": [
        "**Sebelum Lanjut!,   jalankan \"Librari Wrapper-Forward\" di bagian paling bawah**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mU9Zy447yFk3",
        "outputId": "00753c2a-6893-40e8-f3d3-d78209ae77c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "#data_cleanU1.xlsx\n",
        "data = pd.read_excel(\"https://github.com/lufias69/Spam_Detection/blob/master/Filter%20chi%20square/komentar/data_cleanU1.xlsx?raw=true\")\n",
        "# data = data[:200]\n",
        "komentar = data.komentar.tolist()\n",
        "label = data.label.tolist()\n",
        " \n",
        "y = np.array(label)\n",
        "print(len(y))\n",
        " \n",
        "data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>label</th>\n",
              "      <th>komentar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>195</td>\n",
              "      <td>spam</td>\n",
              "      <td>ga nyesel deh aku order sana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>480</td>\n",
              "      <td>non spam</td>\n",
              "      <td>wakakak tolol tulang tulang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>539</td>\n",
              "      <td>non spam</td>\n",
              "      <td>sepatu keren kamu keren cara instan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>564</td>\n",
              "      <td>spam</td>\n",
              "      <td>via q udh blja shoppe barang bagus kecewa mantap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>596</td>\n",
              "      <td>non spam</td>\n",
              "      <td>sir what if use again kamisenglish that s just...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5042</th>\n",
              "      <td>5049</td>\n",
              "      <td>spam</td>\n",
              "      <td>bosen outfit kalian aja yuk cek ig tambah kole...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5043</th>\n",
              "      <td>5050</td>\n",
              "      <td>spam</td>\n",
              "      <td>maantaap banggeet kaak eteaah akuu pakee gemuk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5044</th>\n",
              "      <td>5052</td>\n",
              "      <td>spam</td>\n",
              "      <td>sllu ajar usaha tahan kualitas costumer neng s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5045</th>\n",
              "      <td>5053</td>\n",
              "      <td>spam</td>\n",
              "      <td>aasi ane o a uda nenain odu yan sana eui eecay...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5046</th>\n",
              "      <td>5054</td>\n",
              "      <td>spam</td>\n",
              "      <td>awal ny ga percaya aku coba nyata hasil cepet ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5047 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Column1     label                                           komentar\n",
              "0         195      spam                       ga nyesel deh aku order sana\n",
              "1         480  non spam                        wakakak tolol tulang tulang\n",
              "2         539  non spam                sepatu keren kamu keren cara instan\n",
              "3         564      spam   via q udh blja shoppe barang bagus kecewa mantap\n",
              "4         596  non spam  sir what if use again kamisenglish that s just...\n",
              "...       ...       ...                                                ...\n",
              "5042     5049      spam  bosen outfit kalian aja yuk cek ig tambah kole...\n",
              "5043     5050      spam  maantaap banggeet kaak eteaah akuu pakee gemuk...\n",
              "5044     5052      spam  sllu ajar usaha tahan kualitas costumer neng s...\n",
              "5045     5053      spam  aasi ane o a uda nenain odu yan sana eui eecay...\n",
              "5046     5054      spam  awal ny ga percaya aku coba nyata hasil cepet ...\n",
              "\n",
              "[5047 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoPekKK7cPVf",
        "colab_type": "text"
      },
      "source": [
        "**seleksi fitur menggunakan filter**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHKN9dZzcKNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "sf = ChiSquare(alpha = 0.1)\n",
        "#inisialisasi\n",
        "sf.find_best_features(komentar, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x74HTd1hdzX3",
        "colab_type": "code",
        "outputId": "6fa379b1-9b38-459e-a5fa-551a6781614f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"jumlah fitur terbaik:\",len(sf.best_features),\"dari\",len(sf.fitur), \"fitur\")\n",
        "best_features = sf.best_features\n",
        "sf.data #untuk memunculkan semua data\n",
        "sf.alpha #untuk mengetahui alpha"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jumlah fitur terbaik: 2749 dari 15136 fitur\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38cjhBVIc69C",
        "colab_type": "text"
      },
      "source": [
        "**Seleksi fitur Wrapper-forward**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t9c7riZ-yFk_",
        "outputId": "c3ee1524-c02c-44ab-ae24-8749048dbc60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#ini lama bangets\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "hasil = wrapper(model=MultinomialNB(),vocabs = best_features,  weighting=TfidfVectorizer, corpus=komentar, y=y,n_splits=5, target=1.97)\n",
        " \n",
        "best_fitur = hasil[1]\n",
        "for i in best_fitur:\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2749\n",
            "$.^^.\n",
            "1| 0.5557758392291162\n",
            "2| 0.6316651129929644\n",
            "3| 0.6835725990834961\n",
            "4| 0.7053665525125357\n",
            "5| 0.7204286176883297\n",
            "6| 0.7339031881384372\n",
            "7| 0.7751152498797946\n",
            "8| 0.8044443572206577\n",
            "9| 0.8189080454130646\n",
            "10| 0.8319857912451305\n",
            "11| 0.8412988057973291\n",
            "12| 0.8504126230264255\n",
            "13| 0.8583379289366002\n",
            "14| 0.8650735460067315\n",
            "15| 0.8718103405979845\n",
            "16| 0.8771608003218558\n",
            "17| 0.8829067108891266\n",
            "18| 0.8880597395715786\n",
            "19| 0.8930145521985301\n",
            "20| 0.8965820486904985\n",
            "21| 0.899753309324986\n",
            "22| 0.9025263715667899\n",
            "23| 0.9051025915277355\n",
            "24| 0.9076786152351607\n",
            "25| 0.9102540501820251\n",
            "26| 0.9120379946815296\n",
            "27| 0.9140195664759737\n",
            "28| 0.9160007457633773\n",
            "29| 0.9177841015023207\n",
            "30| 0.9193694374392841\n",
            "31| 0.9209543808692068\n",
            "32| 0.9223415007506697\n",
            "33| 0.9237284243786125\n",
            "34| 0.9249171319510543\n",
            "35| 0.9265020753809772\n",
            "36| 0.9278893915159603\n",
            "37| 0.9290780990884023\n",
            "38| 0.9302668066608446\n",
            "39| 0.9312574944313063\n",
            "40| 0.9322477896947277\n",
            "41| 0.9330406539167297\n",
            "42| 0.9338335181387315\n",
            "43| 0.9346261861072133\n",
            "44| 0.9354190503292154\n",
            "45| 0.9362117182976968\n",
            "46| 0.9370041900126583\n",
            "47| 0.9377966617276197\n",
            "48| 0.9385891334425811\n",
            "49| 0.9393814089040221\n",
            "50| 0.9401736843654633\n",
            "51| 0.9407687250390054\n",
            "52| 0.9415611967539667\n",
            "53| 0.9423530797083671\n",
            "54| 0.9429475316213484\n",
            "55| 0.9435419835343296\n",
            "56| 0.9441364354473109\n",
            "57| 0.944730887360292\n",
            "58| 0.9453253392732732\n",
            "59| 0.9459197911862542\n",
            "60| 0.9465140468457152\n",
            "61| 0.9471081062516559\n",
            "62| 0.9477029506716776\n",
            "63| 0.9482970100776182\n",
            "64| 0.9488910694835588\n",
            "65| 0.9494851288894994\n",
            "66| 0.9500793845489603\n",
            "67| 0.9506738364619414\n",
            "68| 0.9514653269093014\n",
            "69| 0.9520599750758029\n",
            "70| 0.9532486826482449\n",
            "71| 0.9540413506167267\n",
            "72| 0.9544377827277277\n",
            "73| 0.9550320383871886\n",
            "74| 0.9558241175951094\n",
            "75| 0.9564181770010499\n",
            "76| 0.9568146091120509\n",
            "77| 0.9572110412230519\n",
            "78| 0.9576072770805325\n",
            "79| 0.9580035129380133\n",
            "80| 0.958399748795494\n",
            "81| 0.9587959846529748\n",
            "82| 0.9591922205104554\n",
            "83| 0.9595884563679361\n",
            "84| 0.9599844959718965\n",
            "85| 0.9603805355758569\n",
            "86| 0.9607767714333375\n",
            "87| 0.9611732035443386\n",
            "88| 0.961569243148299\n",
            "89| 0.9617676554573198\n",
            "90| 0.9621640875683207\n",
            "91| 0.9625601271722811\n",
            "92| 0.9627583432277816\n",
            "93| 0.962956559283282\n",
            "94| 0.9633525988872425\n",
            "95| 0.963550814942743\n",
            "96| 0.9637490309982436\n",
            "97| 0.963947247053744\n",
            "98| 0.9641454631092445\n",
            "99| 0.964343679164745\n",
            "100| 0.9645418952202455\n",
            "101| 0.9647401112757461\n",
            "102| 0.9649383273312466\n",
            "103| 0.965136543386747\n",
            "104| 0.9653347594422476\n",
            "105| 0.9657306027926875\n",
            "106| 0.9661268386501684\n",
            "107| 0.9663250547056688\n",
            "108| 0.9665232707611693\n",
            "109| 0.9667214868166697\n",
            "110| 0.9669197028721703\n",
            "111| 0.9671179189276708\n",
            "112| 0.9673161349831713\n",
            "113| 0.9677121745871317\n",
            "114| 0.9679103906426322\n",
            "115| 0.9681086066981326\n",
            "116| 0.9683068227536331\n",
            "117| 0.9685050388091335\n",
            "118| 0.9687032548646342\n",
            "119| 0.9689012746666142\n",
            "120| 0.9690992944685946\n",
            "121| 0.9692973142705746\n",
            "122| 0.969693353874535\n",
            "123| 0.9700891972249751\n",
            "124| 0.9704854330824558\n",
            "125| 0.9706834528844361\n",
            "126| 0.9708814726864162\n",
            "127| 0.9710796887419167\n",
            "128| 0.9712777085438968\n",
            "129| 0.9714757283458771\n",
            "130| 0.9716737481478572\n",
            "131| 0.9718717679498375\n",
            "132| 0.9720697877518176\n",
            "133| 0.9722678075537979\n",
            "134| 0.972465827355778\n",
            "135| 0.9726638471577583\n",
            "136| 0.9728618669597384\n",
            "137| 0.9730598867617187\n",
            "138| 0.9732581028172194\n",
            "139| 0.9734563188727197\n",
            "140| 0.9736543386747\n",
            "141| 0.9738525547302006\n",
            "142| 0.9740507707857009\n",
            "143| 0.9742489868412015\n",
            "144| 0.9744470066431816\n",
            "145| 0.9746450264451619\n",
            "146| 0.974843046247142\n",
            "147| 0.9750410660491223\n",
            "148| 0.9752392821046227\n",
            "149| 0.9754373019066029\n",
            "150| 0.9758333415105633\n",
            "151| 0.9760315575660637\n",
            "152| 0.9762297736215644\n",
            "153| 0.9764279896770649\n",
            "154| 0.9766262057325653\n",
            "155| 0.9768244217880658\n",
            "156| 0.9772204613920262\n",
            "157| 0.9774186774475266\n",
            "158| 0.9776168935030272\n",
            "159| 0.9778149133050075\n",
            "160| 0.9780129331069876\n",
            "161| 0.9782109529089679\n",
            "162| 0.978408972710948\n",
            "163| 0.9786069925129283\n",
            "164| 0.9788050123149084\n",
            "165| 0.9790030321168887\n",
            "166| 0.9792010519188687\n",
            "167| 0.9793990717208491\n",
            "168| 0.9799939161408707\n",
            "169| 0.980191935942851\n",
            "170| 0.9803899557448311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sNnA5SntyFlE",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jNoLjYjbyFlJ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jmNI1P8syFlO",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r8Rj-XSPyFlT",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8frkFsAUyFlf",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6YEp-P_nJ1ow"
      },
      "source": [
        "**Librari Wrapper-Forward**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAvinpiKx0F3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        " \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        " \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        " \n",
        "def convert_bin(data, key=False):\n",
        "    new_data = list()\n",
        "    if (type(data)==list or type(data)==str) and key==False:\n",
        "        if type(data)==str:\n",
        "            for d in data:\n",
        "                new_data.append(int(d))\n",
        "        else:\n",
        "            for d in data:\n",
        "                new_data.append(int(d))\n",
        "        return new_data\n",
        "    else:\n",
        "        for d in data:\n",
        "            new_data.append(str(d))\n",
        "        return \"\".join(new_data)\n",
        "            \n",
        "def join_bin(data1, data2):\n",
        "    new_data = list()\n",
        "    for a,b in zip(data1, data2):\n",
        "        if a==b:\n",
        "            new_data.append(a)\n",
        "        elif a!=b:\n",
        "            if b==1:\n",
        "                new_data.append(b)\n",
        "            elif a==1:\n",
        "                new_data.append(a)\n",
        "            else:\n",
        "                new_data.append(0)\n",
        "    return new_data\n",
        " \n",
        "def gen(x, urutan):\n",
        "    first_bin = [0 for i in range(0,x)]\n",
        "    first_bin[urutan]=1\n",
        "    return first_bin\n",
        " \n",
        "def generate_bins(n):\n",
        "    bin_all = list()\n",
        "    for i in range(0,n):\n",
        "        bin_gen = gen(n,i)\n",
        "        bin_all.append(bin_gen)\n",
        "    return bin_all\n",
        " \n",
        "def convert_to_index(data):\n",
        "    new_data = list()\n",
        "    for idx, i in enumerate(data):\n",
        "        if i!=0:\n",
        "            new_data.append(idx)\n",
        "    return new_data\n",
        " \n",
        " \n",
        " \n",
        "def wrapper(vocabs, model=None, weighting=TfidfVectorizer(), corpus=None, y=None,n_splits=5, target=0.97):\n",
        "    \n",
        "    y=np.array(y)\n",
        "    vectorizer = weighting(vocabulary = vocabs)\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "    fitur = np.array(vectorizer.get_feature_names())\n",
        "    panjang_fitur = len(fitur)\n",
        " \n",
        "    print(len(vectorizer.get_feature_names()))\n",
        "    \n",
        "    binari_pertama = generate_bins(panjang_fitur)\n",
        "    scor_binari_pertama = list()\n",
        " \n",
        "    skf = StratifiedKFold(n_splits=n_splits)\n",
        "    skf_split = skf.split(X, y)\n",
        " \n",
        " \n",
        "    print(\"$\",end=\".\")\n",
        "    for b in binari_pertama:\n",
        "        idx_bin = convert_to_index(b)\n",
        "        # print(fitur[idx_bin],end=\"\")\n",
        "        vectorizer = weighting(vocabulary=fitur[idx_bin])\n",
        "        X = vectorizer.fit_transform(corpus)\n",
        "        \n",
        "        skf = StratifiedKFold(n_splits=n_splits)\n",
        "        skor_list = list()\n",
        "        \n",
        "        for train_index, test_index in skf.split(X, y):\n",
        "            # print(X[train_index])\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "            \n",
        "            model.fit(X_train, y_train)\n",
        "            skor_list.append(model.score(X_test,y_test))\n",
        "            \n",
        "        scor_binari_pertama.append(sum(skor_list)/len(skor_list))\n",
        "    print(\"^^\",end=\".\") \n",
        "    print(\"\")\n",
        "    max_index = scor_binari_pertama.index(max(scor_binari_pertama))\n",
        "    pilihan_pertama_bin = binari_pertama[max_index]\n",
        "    print(sum(pilihan_pertama_bin), end=\"| \")\n",
        "    print(max(scor_binari_pertama))\n",
        "    \n",
        "    all_bin = list()\n",
        "    all_skor = list()\n",
        " \n",
        "    best_fitur = list()\n",
        "    best_skor = list()\n",
        "    \n",
        "    for _ in range(panjang_fitur-1):\n",
        "        # print(_, end=\".\")\n",
        "        new_bin_ = list()\n",
        "        \n",
        "        for idx, i in enumerate(binari_pertama):\n",
        "          if convert_bin(i, key=True) != convert_bin(pilihan_pertama_bin, key=True):\n",
        "            # if idx !=pilihan_pertama_bin:\n",
        "            new_bin_.append(join_bin(pilihan_pertama_bin, i))\n",
        "                \n",
        "        # print(sum(new_bin_[0]))\n",
        "        \n",
        "        binari_pertama = list(new_bin_)\n",
        "        scor_binari_pertama = list()\n",
        "        for b in new_bin_:\n",
        "            idx_bin = convert_to_index(b)\n",
        "            vectorizer = weighting(vocabulary=fitur[idx_bin])\n",
        "            X = vectorizer.fit_transform(corpus)\n",
        " \n",
        "            skf = StratifiedKFold(n_splits=n_splits)\n",
        "            skor_list = list()\n",
        "            for train_index, test_index in skf.split(X, y):\n",
        "                X_train, X_test = X[train_index], X[test_index]\n",
        "                y_train, y_test = y[train_index], y[test_index]\n",
        " \n",
        "                model.fit(X_train, y_train)\n",
        "                skor_list.append(model.score(X_test,y_test))\n",
        " \n",
        "            scor_binari_pertama.append(sum(skor_list)/len(skor_list))\n",
        "        #\n",
        "        max_index = scor_binari_pertama.index(max(scor_binari_pertama))\n",
        "        pilihan_pertama_bin = new_bin_[max_index]\n",
        "        print(sum(pilihan_pertama_bin), end=\"| \")\n",
        " \n",
        "        print(max(scor_binari_pertama))\n",
        " \n",
        "        best_fitur.append(fitur[convert_to_index(pilihan_pertama_bin)])\n",
        "        best_skor.append(max(scor_binari_pertama))\n",
        "        \n",
        "        # all_bin += list(new_bin_)\n",
        "        # all_skor += list(scor_binari_pertama)\n",
        "        \n",
        "        if max(scor_binari_pertama) >= target:\n",
        "            return (max(scor_binari_pertama), fitur[convert_to_index(pilihan_pertama_bin)])\n",
        "        elif sum(pilihan_pertama_bin)>= panjang_fitur-1:\n",
        "          return (max(scor_binari_pertama), fitur[convert_to_index(pilihan_pertama_bin)])\n",
        "        \n",
        "    max_index = best_skor.index(max(best_skor))\n",
        "    # pilihan_pertama_bin = new_bin_[max_index]\n",
        "    best_of_dbest_fitur = best_fitur[max_index]\n",
        "    return (max(best_skor), best_of_dbest_fitur)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6HpxM2ubr57",
        "colab_type": "text"
      },
      "source": [
        "****Filter Library****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwjwEejTzd6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        " \n",
        "import pandas as pd\n",
        " \n",
        "#list = array (indexnya 0,1,2, dst) tdk menentukan indexnya di awal, dict = hashmap ('a') harus mengisi key nya\n",
        "def data_separate(y, complement=False):\n",
        "    kelas = sorted(set(y))\n",
        "    dict_index = dict()\n",
        "    for c in kelas:\n",
        "        index = list()\n",
        "        for ix, c_ in enumerate(y):\n",
        "            if complement==False and c==c_:\n",
        "                index.append(ix)\n",
        "            elif complement==True and c!=c_:\n",
        "                index.append(ix)\n",
        "        dict_index.update({c:index})\n",
        "    return dict_index\n",
        " \n",
        "class ChiSquare:\n",
        "    def __init__(self, alpha = 0.001):\n",
        "        self.alpha = alpha\n",
        " \n",
        "        self.nilai_kritis = {\n",
        "            0.1   : 2.71,\n",
        "            0.05 : 3.84,\n",
        "            0.01 : 6.63,\n",
        "            0.005 : 7.88,\n",
        "            0.001 : 10.83\n",
        "        }\n",
        " \n",
        "        if self.alpha not in self.nilai_kritis:\n",
        "            print(self.alpha, \"tidak termasuk dalam tabel nilai kritis\")\n",
        " \n",
        "    def find_best_features(self, data, label, fitur = None):\n",
        " \n",
        "        if fitur == None:\n",
        "            vectorizer = CountVectorizer(binary=True)\n",
        "        else:\n",
        "            vectorizer = CountVectorizer(vocabulary = fitur, binary=True)\n",
        " \n",
        "        X = vectorizer.fit_transform(data)\n",
        "        nchi = X.shape[0]\n",
        "        self.fitur = vectorizer.get_feature_names()\n",
        "        index_doc = data_separate(label)\n",
        "        index_doc_complement = data_separate(label, complement=True)\n",
        " \n",
        "        self.classes = list(set(label))\n",
        " \n",
        "        self.dict_chis = {\"fitur\":self.fitur}\n",
        "        #fitur adalah key, self.fitur (isinya) berasal dr ln 44 mengambil semua fitur\n",
        "        # for c_ in list(reversed(self.classes)):\n",
        "        for c_ in self.classes:\n",
        "            A = np.sum(X[index_doc[c_]], axis=0).A\n",
        "            B = X[index_doc[c_]].shape[0] - A\n",
        " \n",
        "            C = np.sum(X[index_doc_complement[c_]], axis=0).A\n",
        "            D = X[index_doc_complement[c_]].shape[0] - C\n",
        " \n",
        "            AD = A*D\n",
        "            CB = C*B\n",
        " \n",
        "            atas = nchi * (AD - CB)**2\n",
        "            bawah = (A + C) * (B + D) * (A + B) * (C + D)\n",
        "            x_pangkat2 = atas/bawah\n",
        "            # print(atas, bawah)\n",
        "            self.dict_chis.update({c_:list(x_pangkat2[0])})\n",
        "            #memasukkan hasil perhitungan untuk setiap kelas disimpan dalam dict dimana key nya adalah kelasnya (c_)\n",
        "            #kalo di pyton berbasis objec, object akan bicara memory\n",
        "            # print(A, B, C, D, \"| \")\n",
        "            # print(\"=================================================\")\n",
        "        self.best_features = list()\n",
        "        nk = self.nilai_kritis[self.alpha] #Ini adalah implemenasi dari dictionary\n",
        "        # print(self.dict_chis[self.classes[0]])\n",
        "        for term, sp, nsp in zip(self.fitur, self.dict_chis[self.classes[0]], self.dict_chis[self.classes[1]]):\n",
        "            #akan dicek satu per satu fitur\n",
        "            #zip --> menyatukan beberapa list atau array, classes[0] adalah spam -> mengambil data chisquare utk kelas spam, classes[1] adalah nonspam\n",
        "            # print(sp, nsp)\n",
        "            if sp>=nk or nsp>=nk:\n",
        "                self.best_features.append(term)\n",
        " \n",
        "        self.data = pd.DataFrame.from_dict(self.dict_chis)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}