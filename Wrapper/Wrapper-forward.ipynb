{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CzjTelUVyFkv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Del3hgyTNEk5"
   },
   "source": [
    "**Sebelum Lanjut!,   jalankan \"Librari Wrapper-Forward\" di bagian paling bawah**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "mU9Zy447yFk3",
    "outputId": "cbc7849c-5b16-48ca-dcc6-c06473f0cb2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5047\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>label</th>\n",
       "      <th>komentar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>spam</td>\n",
       "      <td>ga nyesel deh aku order sana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>non spam</td>\n",
       "      <td>wakakak tolol tulang tulang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>539</td>\n",
       "      <td>non spam</td>\n",
       "      <td>sepatu keren kamu keren cara instan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>564</td>\n",
       "      <td>spam</td>\n",
       "      <td>via q udh blja shoppe barang bagus kecewa mantap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>596</td>\n",
       "      <td>non spam</td>\n",
       "      <td>sir what if use again kamisenglish that s just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5042</td>\n",
       "      <td>5049</td>\n",
       "      <td>spam</td>\n",
       "      <td>bosen outfit kalian aja yuk cek ig tambah kole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5043</td>\n",
       "      <td>5050</td>\n",
       "      <td>spam</td>\n",
       "      <td>maantaap banggeet kaak eteaah akuu pakee gemuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5044</td>\n",
       "      <td>5052</td>\n",
       "      <td>spam</td>\n",
       "      <td>sllu ajar usaha tahan kualitas costumer neng s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5045</td>\n",
       "      <td>5053</td>\n",
       "      <td>spam</td>\n",
       "      <td>aasi ane o a uda nenain odu yan sana eui eecay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5046</td>\n",
       "      <td>5054</td>\n",
       "      <td>spam</td>\n",
       "      <td>awal ny ga percaya aku coba nyata hasil cepet ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5047 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Column1     label                                           komentar\n",
       "0         195      spam                       ga nyesel deh aku order sana\n",
       "1         480  non spam                        wakakak tolol tulang tulang\n",
       "2         539  non spam                sepatu keren kamu keren cara instan\n",
       "3         564      spam   via q udh blja shoppe barang bagus kecewa mantap\n",
       "4         596  non spam  sir what if use again kamisenglish that s just...\n",
       "...       ...       ...                                                ...\n",
       "5042     5049      spam  bosen outfit kalian aja yuk cek ig tambah kole...\n",
       "5043     5050      spam  maantaap banggeet kaak eteaah akuu pakee gemuk...\n",
       "5044     5052      spam  sllu ajar usaha tahan kualitas costumer neng s...\n",
       "5045     5053      spam  aasi ane o a uda nenain odu yan sana eui eecay...\n",
       "5046     5054      spam  awal ny ga percaya aku coba nyata hasil cepet ...\n",
       "\n",
       "[5047 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_cleanU1.xlsx\n",
    "data = pd.read_excel(\"https://github.com/lufias69/Spam_Detection/blob/master/Filter%20chi%20square/komentar/data_cleanU1.xlsx?raw=true\")\n",
    "komentar = data.komentar.tolist()\n",
    "label = data.label.tolist()\n",
    "\n",
    "y = np.array(label)\n",
    "print(len(y))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "t9c7riZ-yFk_",
    "outputId": "7ef6922e-e177-473c-8592-9b8b8bb0295b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$."
     ]
    }
   ],
   "source": [
    "#ini lama bangets\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "hasil = wrapper(model=MultinomialNB(), weighting=TfidfVectorizer, corpus=komentar, y=y,n_splits=5, target=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "sNnA5SntyFlE",
    "outputId": "6363660f-c7d3-4329-a2ba-bd8df398a4ca"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-556728356165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_fitur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasil\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_fitur\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hasil' is not defined"
     ]
    }
   ],
   "source": [
    "best_fitur = hasil[1]\n",
    "\n",
    "for i in best_fitur:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNoLjYjbyFlJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmNI1P8syFlO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8Rj-XSPyFlT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8frkFsAUyFlf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YEp-P_nJ1ow"
   },
   "source": [
    "**Librari Wrapper-Forward**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zp5IaWKUyFlo"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def convert_bin(data, key=False):\n",
    "    new_data = list()\n",
    "    if (type(data)==list or type(data)==str) and key==False:\n",
    "        if type(data)==str:\n",
    "            for d in data:\n",
    "                new_data.append(int(d))\n",
    "        else:\n",
    "            for d in data:\n",
    "                new_data.append(int(d))\n",
    "        return new_data\n",
    "    else:\n",
    "        for d in data:\n",
    "            new_data.append(str(d))\n",
    "        return \"\".join(new_data)\n",
    "            \n",
    "def join_bin(data1, data2):\n",
    "    new_data = list()\n",
    "    for a,b in zip(data1, data2):\n",
    "        if a==b:\n",
    "            new_data.append(a)\n",
    "        elif a!=b:\n",
    "            if b==1:\n",
    "                new_data.append(b)\n",
    "            elif a==1:\n",
    "                new_data.append(a)\n",
    "            else:\n",
    "                new_data.append(0)\n",
    "    return new_data\n",
    "\n",
    "def gen(x, urutan):\n",
    "    first_bin = [0 for i in range(0,x)]\n",
    "    first_bin[urutan]=1\n",
    "    return first_bin\n",
    "\n",
    "def generate_bins(n):\n",
    "    bin_all = list()\n",
    "    for i in range(0,n):\n",
    "        bin_gen = gen(n,i)\n",
    "        bin_all.append(bin_gen)\n",
    "    return bin_all\n",
    "\n",
    "def convert_to_index(data):\n",
    "    new_data = list()\n",
    "    for idx, i in enumerate(data):\n",
    "        if i!=0:\n",
    "            new_data.append(idx)\n",
    "    return new_data\n",
    "\n",
    "\n",
    "\n",
    "def wrapper(model=None, weighting=TfidfVectorizer(), corpus=None, y=None,n_splits=5, target=0.97):\n",
    "    \n",
    "    y=np.array(y)\n",
    "    vectorizer = weighting()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    fitur = np.array(vectorizer.get_feature_names())\n",
    "    panjang_fitur = len(fitur)\n",
    "    \n",
    "    binari_pertama = generate_bins(panjang_fitur)\n",
    "    scor_binari_pertama = list()\n",
    "    print(\"$\",end=\".\")\n",
    "    for b in binari_pertama:\n",
    "        idx_bin = convert_to_index(b)\n",
    "        # print(fitur[idx_bin],end=\"\")\n",
    "        vectorizer = weighting(vocabulary=fitur[idx_bin])\n",
    "        X = vectorizer.fit_transform(corpus)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=n_splits)\n",
    "        skor_list = list()\n",
    "        \n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            skor_list.append(model.score(X_test,y_test))\n",
    "            \n",
    "        scor_binari_pertama.append(sum(skor_list)/len(skor_list))\n",
    "    print(\"^^\",end=\".\")  \n",
    "    max_index = scor_binari_pertama.index(max(scor_binari_pertama))\n",
    "    pilihan_pertama_bin = binari_pertama[max_index]\n",
    "    print(max(scor_binari_pertama))\n",
    "    \n",
    "    all_bin = list()\n",
    "    all_skor = list()\n",
    "    \n",
    "    for _ in range(panjang_fitur-1):\n",
    "        print(_, end=\".\")\n",
    "        new_bin_ = list()\n",
    "        for idx, i in enumerate(binari_pertama):\n",
    "            if idx !=pilihan_pertama_bin:\n",
    "                new_bin_.append(join_bin(convert_bin(pilihan_pertama_bin, key=True), i)) \n",
    "                \n",
    "        binari_pertama = list(new_bin_)\n",
    "                \n",
    "#fdsf\n",
    "        scor_binari_pertama = list()\n",
    "        for b in new_bin_:\n",
    "            idx_bin = convert_to_index(b)\n",
    "            vectorizer = weighting(vocabulary=fitur[idx_bin])\n",
    "            X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "            skf = StratifiedKFold(n_splits=n_splits)\n",
    "            skor_list = list()\n",
    "            for train_index, test_index in skf.split(X, y):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                skor_list.append(model.score(X_test,y_test))\n",
    "\n",
    "            scor_binari_pertama.append(sum(skor_list)/len(skor_list))\n",
    "        #\n",
    "        max_index = scor_binari_pertama.index(max(scor_binari_pertama))\n",
    "        pilihan_pertama_bin = convert_bin(new_bin_[max_index], key=False) \n",
    "        print(max(scor_binari_pertama))\n",
    "        \n",
    "        all_bin += list(new_bin_)\n",
    "        all_skor += list(scor_binari_pertama)\n",
    "        \n",
    "        if max(scor_binari_pertama) >= target:\n",
    "            return (max(scor_binari_pertama), fitur[convert_to_index(pilihan_pertama_bin)])\n",
    "        elif sum(pilihan_pertama_bin)>= panjang_fitur-1:\n",
    "            return (max(scor_binari_pertama), fitur[convert_to_index(pilihan_pertama_bin)])\n",
    "        \n",
    "    max_index = all_skor.index(max(all_skor))\n",
    "    pilihan_pertama_bin =  convert_bin(all_bin[max_index], key=False) \n",
    "    return (max(all_skor), fitur[convert_to_index(pilihan_pertama_bin)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10111'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_bin([1,0,1,1,1], key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_bin('10111', key=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
